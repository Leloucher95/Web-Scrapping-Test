Voici le fichier Markdown complet et d√©taill√© pour ton projet de web scraping BrainyQuote :

```markdown
# üìö BrainyQuote Web Scraper - Documentation Compl√®te

## üéØ Vue d'ensemble du projet

Application de web scraping moderne permettant d'extraire automatiquement des citations de BrainyQuote.com selon des sujets sp√©cifi√©s. Le syst√®me combine un backend Python robuste avec une interface frontend Nuxt.js, utilisant Supabase comme solution de base de donn√©es et de stockage [web:26][web:27].

### üöÄ Fonctionnalit√©s principales

- **Extraction intelligente** : Scraping automatis√© avec gestion de pagination
- **Interface moderne** : Frontend Nuxt.js responsive et intuitive
- **Temps r√©el** : Suivi de progression en direct via WebSockets
- **Stockage cloud** : Base de donn√©es Supabase et stockage d'images
- **Export flexible** : Donn√©es exportables en CSV/JSON
- **Gestion d'erreurs** : Syst√®me robuste avec logging centralis√©

## üèóÔ∏è Architecture Technique

### Architecture globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Backend      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Supabase     ‚îÇ
‚îÇ   (Nuxt.js)     ‚îÇ     ‚îÇ   (FastAPI)     ‚îÇ     ‚îÇ  (PostgreSQL)   ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ - Interface     ‚îÇ     ‚îÇ - Playwright    ‚îÇ     ‚îÇ - Donn√©es       ‚îÇ
‚îÇ - WebSockets    ‚îÇ     ‚îÇ - Scraping      ‚îÇ     ‚îÇ - Images        ‚îÇ
‚îÇ - Export CSV    ‚îÇ     ‚îÇ - API REST      ‚îÇ     ‚îÇ - Auth          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack technique

#### Backend
- **Langage** : Python 3.9+
- **Framework** : FastAPI (API REST haute performance)
- **Scraping** : Playwright (automatisation navigateur)
- **Base de donn√©es** : Supabase (PostgreSQL managed)
- **Stockage** : Supabase Storage
- **Communication** : WebSockets pour temps r√©el

#### Frontend
- **Framework** : Nuxt.js 3 avec TypeScript
- **UI** : Tailwind CSS + Headless UI
- **√âtat** : Pinia stores
- **Communication** : Axios + Socket.io-client
- **Build** : Vite (int√©gr√© Nuxt 3)

## üìÅ Structure de Projet Optimale

### Structure monorepo recommand√©e [web:21][web:23]

```
brainyquote-scraper/
‚îú‚îÄ‚îÄ üìÑ README.md                    # Documentation principale
‚îú‚îÄ‚îÄ üìÑ PROJECT.md                   # Ce fichier
‚îú‚îÄ‚îÄ üìÑ .gitignore                   # Ignore files
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml           # Orchestration containers
‚îú‚îÄ‚îÄ üìÑ .env.example                 # Variables d'environnement
‚îÇ
‚îú‚îÄ‚îÄ üìÇ frontend/                    # Application Nuxt.js
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ ui/                  # Composants UI r√©utilisables
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Button.vue
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Input.vue
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Modal.vue
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ProgressBar.vue
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ forms/               # Composants formulaires
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TopicForm.vue
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ExportForm.vue
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ scraping/            # Composants sp√©cifiques scraping
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ScrapingStatus.vue
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ QuotesList.vue
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ProgressIndicator.vue
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÇ layout/              # Composants layout
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Header.vue
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Footer.vue
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ Sidebar.vue
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ pages/                   # Pages Nuxt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.vue               # Page principale
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ results.vue             # Affichage r√©sultats
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ history.vue             # Historique scraping
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ layouts/                 # Layouts globaux
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ default.vue
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ stores/                  # Pinia stores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping.ts             # √âtat scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quotes.ts               # Gestion citations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui.ts                   # √âtat interface
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ composables/             # Composables Vue
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useScraping.ts          # Logique scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useWebSocket.ts         # WebSocket client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useSupabase.ts          # Client Supabase
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useExport.ts            # Export donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ plugins/                 # Plugins Nuxt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supabase.client.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ socket.client.ts
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ middleware/              # Middlewares
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.ts
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ types/                   # Types TypeScript
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quotes.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.ts
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ utils/                   # Utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ formatters.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constants.ts
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ assets/                  # Assets statiques
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ css/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ images/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÇ icons/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ nuxt.config.ts           # Configuration Nuxt
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ tailwind.config.js       # Configuration Tailwind
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ package.json
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ tsconfig.json
‚îÇ
‚îú‚îÄ‚îÄ üìÇ backend/                     # Application FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ core/                # Configuration centrale
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Variables configuration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py           # Configuration logging
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py       # Exceptions personnalis√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ models/              # Mod√®les de donn√©es
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quote.py            # Mod√®le Citation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping_job.py     # Mod√®le Job scraping
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user.py             # Mod√®le Utilisateur
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ schemas/             # Sch√©mas Pydantic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quote.py            # Sch√©mas citations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping.py         # Sch√©mas scraping
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ common.py           # Sch√©mas communs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ services/            # Services m√©tier
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper_service.py  # Logique scraping
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database_service.py # Interactions DB
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage_service.py  # Gestion fichiers
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export_service.py   # Export donn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ scraper/             # Module scraping
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ brainyquote.py      # Scraper BrainyQuote
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ browser.py          # Gestion navigateur
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extractor.py        # Extraction donn√©es
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py            # Utilitaires scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ api/                 # Endpoints API
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py           # Router principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ v1/              # Version 1 API
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping.py     # Endpoints scraping
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quotes.py       # Endpoints citations
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export.py       # Endpoints export
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py     # D√©pendances API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ database/            # Base de donn√©es
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection.py       # Connexion Supabase
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/       # Repositories
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quote_repo.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ job_repo.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ migrations/         # Migrations SQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ websocket/           # WebSocket manager
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager.py          # Gestionnaire connexions
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ events.py           # Types d'√©v√©nements
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ utils/               # Utilitaires backend
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ formatters.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ helpers.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ main.py              # Point d'entr√©e FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ tests/                   # Tests backend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ unit/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_scraper.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_services.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÇ integration/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_database.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÇ e2e/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ test_full_workflow.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ scripts/                 # Scripts utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ setup_db.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ seed_data.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ migrate.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ requirements.txt         # D√©pendances Python
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ requirements-dev.txt     # D√©pendances d√©veloppement
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Dockerfile              # Image Docker backend
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ .env.example            # Variables environnement
‚îÇ
‚îú‚îÄ‚îÄ üìÇ shared/                      # Code partag√©
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ types/                   # Types partag√©s
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quote.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.ts
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ constants/               # Constantes partag√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraping.ts
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ utils/                   # Utilitaires partag√©s
‚îÇ       ‚îî‚îÄ‚îÄ validation.ts
‚îÇ
‚îú‚îÄ‚îÄ üìÇ database/                    # Sch√©mas base de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ migrations/              # Migrations Supabase
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 001_initial_schema.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 002_add_indexes.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 003_add_jobs_table.sql
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ seeds/                   # Donn√©es test
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_quotes.sql
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ schema.sql               # Sch√©ma complet
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/                        # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ api.md                   # Documentation API
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ deployment.md            # Guide d√©ploiement
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ development.md           # Guide d√©veloppement
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ architecture.md          # Architecture d√©taill√©e
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ assets/                  # Assets documentation
‚îÇ       ‚îî‚îÄ‚îÄ üìÇ images/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ deploy/                      # Scripts d√©ploiement
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ docker-compose.prod.yml
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ kubernetes/              # Manifestes K8s
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ terraform/               # Infrastructure IaC
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ github-actions/          # Workflows CI/CD
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ frontend.yml
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ backend.yml
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ e2e-tests.yml
‚îÇ
‚îî‚îÄ‚îÄ üìÇ tools/                       # Outils d√©veloppement
    ‚îú‚îÄ‚îÄ üìÇ scripts/                 # Scripts utilitaires
    ‚îÇ   ‚îú‚îÄ‚îÄ setup.sh
    ‚îÇ   ‚îú‚îÄ‚îÄ test.sh
    ‚îÇ   ‚îî‚îÄ‚îÄ build.sh
    ‚îî‚îÄ‚îÄ üìÇ configs/                 # Configurations outils
        ‚îú‚îÄ‚îÄ eslint.config.js
        ‚îú‚îÄ‚îÄ prettier.config.js
        ‚îî‚îÄ‚îÄ pytest.ini
```

## üóÑÔ∏è Sch√©ma de Base de Donn√©es

### Tables Supabase

```
-- Table des citations
CREATE TABLE quotes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    author VARCHAR(255) NOT NULL,
    text TEXT NOT NULL,
    topic VARCHAR(100) NOT NULL,
    source_url VARCHAR(500),
    image_url VARCHAR(500),
    image_path VARCHAR(500),  -- Chemin Supabase Storage
    scraped_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    -- Index pour recherche optimis√©e
    UNIQUE(author, text, topic)
);

-- Table des jobs de scraping
CREATE TABLE scraping_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    topic VARCHAR(100) NOT NULL,
    status VARCHAR(50) DEFAULT 'pending', -- pending, running, completed, failed
    total_quotes INTEGER DEFAULT 0,
    processed_quotes INTEGER DEFAULT 0,
    error_message TEXT,
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Table des utilisateurs (optionnel, pour authentification future)
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Index pour performance
CREATE INDEX idx_quotes_topic ON quotes(topic);
CREATE INDEX idx_quotes_author ON quotes(author);
CREATE INDEX idx_quotes_created_at ON quotes(created_at);
CREATE INDEX idx_scraping_jobs_status ON scraping_jobs(status);
CREATE INDEX idx_scraping_jobs_created_at ON scraping_jobs(created_at);
```

### Bucket Supabase Storage

```
-- Bucket pour images de citations
INSERT INTO storage.buckets (id, name, public)
VALUES ('quote-images', 'quote-images', true);

-- Politique d'acc√®s lecture publique
CREATE POLICY "Public Access" ON storage.objects
FOR SELECT USING (bucket_id = 'quote-images');

-- Politique d'√©criture pour service
CREATE POLICY "Service Upload" ON storage.objects
FOR INSERT WITH CHECK (bucket_id = 'quote-images');
```

## ‚öôÔ∏è Configuration D√©taill√©e

### Configuration Backend (.env)

```
# FastAPI
DEBUG=True
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,https://yourapp.vercel.app

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# Playwright
PLAYWRIGHT_BROWSERS_PATH=/usr/lib/playwright
PLAYWRIGHT_HEADLESS=True
PLAYWRIGHT_TIMEOUT=30000

# Scraping
MAX_CONCURRENT_PAGES=3
REQUEST_DELAY=1000
RETRY_ATTEMPTS=3
RETRY_DELAY=2000

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=logs/app.log

# Redis (pour cache/queues futures)
REDIS_URL=redis://localhost:6379

# Monitoring
SENTRY_DSN=your-sentry-dsn
```

### Configuration Frontend (nuxt.config.ts)

```
export default defineNuxtConfig({
  // D√©veloppement
  devtools: { enabled: true },
  typescript: { typeCheck: true },

  // Modules
  modules: [
    '@nuxtjs/tailwindcss',
    '@pinia/nuxt',
    '@vueuse/nuxt',
    '@nuxtjs/color-mode'
  ],

  // CSS Framework
  css: ['~/assets/css/main.css'],

  // Variables d'environnement publiques
  runtimeConfig: {
    // Priv√©es (c√¥t√© serveur)
    supabaseServiceKey: process.env.SUPABASE_SERVICE_ROLE_KEY,

    // Publiques (c√¥t√© client)
    public: {
      supabaseUrl: process.env.SUPABASE_URL,
      supabaseAnonKey: process.env.SUPABASE_ANON_KEY,
      apiBaseUrl: process.env.API_BASE_URL || 'http://localhost:8000',
      wsUrl: process.env.WS_URL || 'ws://localhost:8000/ws'
    }
  },

  // Configuration build
  nitro: {
    preset: 'vercel' // ou 'netlify', 'node-server'
  },

  // Proxy API pour d√©veloppement
  nitro: {
    devProxy: {
      '/api': {
        target: 'http://localhost:8000',
        changeOrigin: true
      }
    }
  }
})
```

## üöÄ Guide de D√©marrage Rapide

### Pr√©requis syst√®me

```
# Versions recommand√©es
Node.js >= 18.0.0
Python >= 3.9.0
Git >= 2.30.0
Docker >= 20.10.0 (optionnel)
```

### Installation compl√®te

```
# 1. Cloner le repository
git clone https://github.com/Leloucher95/brainyquote-scraper.git
cd brainyquote-scraper

# 2. Setup backend
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
playwright install

# 3. Setup frontend
cd ../frontend
npm install

# 4. Configuration environnement
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env
# √âditer les fichiers .env avec tes credentials Supabase

# 5. Setup base de donn√©es
cd backend
python scripts/setup_db.py

# 6. Lancement d√©veloppement
# Terminal 1 - Backend
cd backend
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2 - Frontend
cd frontend
npm run dev

# L'application sera accessible sur http://localhost:3000
```

### Docker (alternative)

```
# docker-compose.yml
version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
    volumes:
      - ./backend:/app
    command: uvicorn src.main:app --reload --host 0.0.0.0 --port 8000

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NUXT_PUBLIC_API_BASE_URL=http://backend:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev
    depends_on:
      - backend

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
```

```
# Lancement avec Docker
docker-compose up -d
```

## üõ†Ô∏è Workflow de D√©veloppement

### √âtapes de d√©veloppement recommand√©es [web:23]

1. **Phase Setup** (Jour 1-2)
   - Configuration repository et environnements
   - Setup Supabase projet et sch√©ma DB
   - Configuration outils d√©veloppement

2. **Phase Backend Core** (Jour 3-7)
   - D√©veloppement scraper Playwright
   - Int√©gration Supabase (DB + Storage)
   - API FastAPI et WebSocket

3. **Phase Frontend Core** (Jour 8-12)
   - Interface Nuxt.js et composants
   - Int√©gration API et temps r√©el
   - Export et gestion erreurs

4. **Phase Tests & Polish** (Jour 13-15)
   - Tests unitaires et int√©gration
   - Optimisation performance
   - Documentation et d√©ploiement

### Branching Strategy - Trunk-based Development [web:23]

```
main (trunk)
‚îú‚îÄ‚îÄ feature/scraper-core
‚îú‚îÄ‚îÄ feature/frontend-ui
‚îú‚îÄ‚îÄ feature/realtime-progress
‚îî‚îÄ‚îÄ hotfix/scraping-timeout
```

**R√®gles :**
- Branches courtes (max 2-3 jours)
- Pull requests obligatoires
- Tests automatis√©s sur chaque PR
- D√©ploiement automatique depuis main

### Scripts de d√©veloppement

```
// package.json scripts recommand√©s
{
  "scripts": {
    "dev": "concurrently \"npm run dev:backend\" \"npm run dev:frontend\"",
    "dev:backend": "cd backend && uvicorn src.main:app --reload",
    "dev:frontend": "cd frontend && npm run dev",
    "test": "npm run test:backend && npm run test:frontend",
    "test:backend": "cd backend && pytest",
    "test:frontend": "cd frontend && npm run test",
    "build": "npm run build:backend && npm run build:frontend",
    "build:backend": "cd backend && docker build -t brainyquote-backend .",
    "build:frontend": "cd frontend && npm run build",
    "lint": "npm run lint:backend && npm run lint:frontend",
    "lint:backend": "cd backend && flake8 src/",
    "lint:frontend": "cd frontend && eslint .",
    "format": "npm run format:backend && npm run format:frontend",
    "format:backend": "cd backend && black src/",
    "format:frontend": "cd frontend && prettier --write ."
  }
}
```

## üìä Gestion des Performances

### Optimisations Scraping

```
# backend/src/scraper/browser.py
class OptimizedBrowser:
    def __init__(self):
        self.browser_config = {
            'headless': True,
            'args': [
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-gpu',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
        }

    async def create_context(self):
        return await self.browser.new_context(
            viewport={'width': 1280, 'height': 720},
            user_agent='Mozilla/5.0 (compatible; ScraperBot/1.0)'
        )
```

### Cache et Optimisations Frontend

```
// frontend/composables/useCache.ts
export const useCache = () => {
  const cache = new Map()

  const getCachedQuotes = (topic: string) => {
    return cache.get(topic)
  }

  const setCachedQuotes = (topic: string, quotes: Quote[]) => {
    cache.set(topic, {
      data: quotes,
      timestamp: Date.now(),
      ttl: 300000 // 5 minutes
    })
  }

  return { getCachedQuotes, setCachedQuotes }
}
```

## üîê S√©curit√© et Bonnes Pratiques

### S√©curit√© Backend

```
# backend/src/core/security.py
from fastapi import HTTPException, Security
from fastapi.security import HTTPBearer

security = HTTPBearer()

async def verify_api_key(token: str = Security(security)):
    if token.credentials != settings.API_SECRET_KEY:
        raise HTTPException(
            status_code=403,
            detail="Invalid API key"
        )
    return token.credentials
```

### Variables d'environnement s√©curis√©es [web:27]

```
# Production uniquement - Ne jamais commiter
SUPABASE_SERVICE_ROLE_KEY=xxxx
API_SECRET_KEY=xxxx
SENTRY_DSN=xxxx

# D√©veloppement
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=xxx  # Cl√© publique, OK
```

## üöÄ D√©ploiement Production

### Options de d√©ploiement recommand√©es [web:27]

#### 1. Vercel (Recommand√© pour MVP)
```
# Frontend
npx vercel --prod

# Backend (Vercel Functions)
# Structure sp√©cifique requise dans /api
```

#### 2. Railway/Render
```
# railway.toml
[build]
builder = "nixpacks"

[deploy]
restartPolicyType = "on-failure"
restartPolicyMaxRetries = 10
```

#### 3. Docker + VPS
```
# backend/Dockerfile
FROM python:3.9-slim

RUN apt-get update && apt-get install -y \
    chromium \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY src/ src/
EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### CI/CD GitHub Actions

```
# .github/workflows/deploy.yml
name: Deploy

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Test Backend
        run: |
          cd backend
          pip install -r requirements.txt
          pytest

      - name: Test Frontend
        run: |
          cd frontend
          npm install
          npm run test

  deploy-backend:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Railway
        uses: railway/actions@v1
        with:
          railway-token: ${{ secrets.RAILWAY_TOKEN }}

  deploy-frontend:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Vercel
        uses: vercel/actions@v1
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
```

## üß™ Strat√©gie de Tests

### Tests Backend (Pytest)

```
# backend/tests/test_scraper.py
import pytest
from src.scraper.brainyquote import BrainyQuoteScraper

@pytest.mark.asyncio
async def test_scraper_extract_quotes():
    scraper = BrainyQuoteScraper()
    quotes = await scraper.scrape_topic("motivation", limit=5)

